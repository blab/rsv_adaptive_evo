Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job          count    min threads    max threads
---------  -------  -------------  -------------
align            1              1              1
all              1              1              1
ancestral        1              1              1
export           1              1              1
filter           1              1              1
parse            1              1              1
refine           1              1              1
traits           1              1              1
translate        1              1              1
tree             1              1              1
total           10              1              1

Select jobs to execute...

[Mon Jan 24 12:31:35 2022]
Job 6: Parsing fasta into sequences and metadata

[Mon Jan 24 12:31:38 2022]
Finished job 6.
1 of 10 steps (10%) done
Select jobs to execute...

[Mon Jan 24 12:31:38 2022]
Job 5: 
        Filtering to
          - 50 sequence(s) per country year month
          - excluding strains in config/dropped_strains.txt
        

[Mon Jan 24 12:31:40 2022]
Error in rule filter:
    jobid: 5
    output: results/filtered.fasta
    shell:
        
        augur filter             --sequences results/sequences.fasta             --metadata results/metadata.tsv             --output results/filtered.fasta             -- exclude config/dropped_strains.txt             --group-by country year month             --sequences-per-group 50 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/katekistler/nextstrain/rsv/.snakemake/log/2022-01-24T123134.599854.snakemake.log
