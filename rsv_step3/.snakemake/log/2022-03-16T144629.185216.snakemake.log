Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                 count    min threads    max threads
----------------  -------  -------------  -------------
all                     1              1              1
infer_insertions        1              1              1
total                   2              1              1

Select jobs to execute...

[Wed Mar 16 14:46:29 2022]
rule infer_insertions:
    input: results/insertions_A.tsv, results/tree_A.nwk
    output: results/insertions_A.json
    log: logs/infer_insertions_A.txt
    jobid: 9
    wildcards: subtype=A
    resources: tmpdir=/var/folders/g_/6938g_6s199gxxswt2nf7w500000gn/T

[Wed Mar 16 14:46:30 2022]
Error in rule infer_insertions:
    jobid: 9
    output: results/insertions_A.json
    log: logs/infer_insertions_A.txt (check log file(s) for error message)
    shell:
        
        python3 scripts/reconstruct_insertions.py             --insertions results/insertions_A.tsv             --tree results/tree_A.nwk             --output results/insertions_A.json 2>&1 | tee logs/infer_insertions_A.txt
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/katekistler/nextstrain/rsv_testing/.snakemake/log/2022-03-16T144629.185216.snakemake.log
